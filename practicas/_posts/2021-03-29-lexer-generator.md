---
title: Lexer Generator
published: true
categories: ["practicas"]
rubrica:
video:
  clase20200401: gO49wnWoE_s 
  clase20200325: 4jmsZbEpW7g
  clase20200324: xCNs1fT1KOc
---

## Objetivos

Usando el repo de la asignaci√≥n de esta tarea construya un paquete npm y 
publ√≠quelo como paquete privado en GitHub Registry con √°mbito `@ULL-ESIT-PL-2021`  y con nombre el nombre de su repo `lexgen-code-aluAtGitHub`

Una parte de los conceptos y habilidades a ejercitar con esta pr√°ctica se explican en la secci√≥n [Creating and publishing a node.js module en GitHub y en NPM]({{site.baseurl}}/assets/temas/introduccion-a-javascript/creating-and-publishing-npm-module). 

El m√≥dulo deber√° exportar una funci√≥n que construye analizadores l√©xicos:

```js
const buildLexer =require('@ULL-ESIT-PL-2021/lexgen-code-aluAtGitHub');
```

La funci√≥n `buildLexer` se llamar√° con un array de pares 

```js 
const myTokens = [ 
  [`nombreToken1`: /regexpToken1/], 
  [`nombreToken2`: /regexpToken2/],
  ... 
]
``` 

que describe el l√©xico del lenguaje y retornar√° una funci√≥n `lexer` que es el analizador l√©xico:

```js
const lexer = buildLexer(myTokens);
```

Se establecen las siguientes consideraciones sem√°nticas:

* Si un token tiene de nombre `SPACE` sus matching ser√°n ignorados y no se a√±adir√°n a la lista de tokens 
* El nombre de token `ERROR` es *palabra reservada* y no deber√≠a ser usado por los clientes de la librer√≠a y es autom√°ticamente generado por los analizadores l√©xicos producidos en caso de que se produzca un error. [V√©ase el √∫ltimo ejemplo con errores en la secci√≥n Pruebas](#pruebas)

Este es un ejemplo mas concreto de como usar la librer√≠a:

```js
const buildLexer = require('@ull-esit-pl-1920/p10-t2-lexgen-code-aluXXX');

const SPACE = /(?<SPACE>\s+|\/\/.*)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>\b([a-z_]\w*))\b/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const myTokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID],
  ['STRING', STRING], ['OP', OP]
];

const lexer = buildLexer(myTokens);
```

cuando `lexer` es llamada con una cadena de entrada retorna la secuencia de tokens de esa cadena conforme a la descripci√≥n l√©xica prove√≠da:

```js
str = 'const varName = "value"';
r = lexer(str);
let expected = [
  { type: 'RESERVEDWORD', value: 'const' },
  { type: 'ID', value: 'varName' },
  { type: 'OP', value: '=' },
  { type: 'STRING', value: '"value"' }
];

test(str, () => {
  expect(r).toEqual(expected);
});
```

Cuando se encuentra una entrada err√≥nea `lexer ` produce un token con nombre `ERROR`:

```js
str = ' // Entrada con errores\nlet x = 42*c';
r = lexer(str);
expected = [
  { type: 'RESERVEDWORD', value: 'let' },
  { type: 'ID', value: 'x' },
  { type: 'OP', value: '=' },
  { type: 'ERROR', value: '42*c' }
];
```

## Prerequisitos

T√≥me esta pr√°ctica con calma por cuanto me parece es  complicada en el estado de conocimientos de RegExps en el que estamos. 
Nos ha faltado una clase para establecer las bases necesarias.

En este v√≠deo se introducen los conceptos de expresiones regulares que son necesarios
para la realizaci√≥n de esta pr√°ctica. Especialmente 

* `lastindex` en el minuto 19:30 
* El uso de la sticky flag `/y` a partir del minuto 30
* Construcci√≥n de analizador l√©xico minuto 33:45

{% include video provider="youtube" id="xCNs1fT1KOc" %} <!-- 2020/03/24 -->

En  los primeros 25 minutos de este v√≠deo se explica como realizar la pr√°ctica:

* Analizadores L√©xicos: 03:00

{% include video provider="youtube" id="4jmsZbEpW7g" %} <!-- 2020/03/25-->

Est√∫dielos antes de seguir adelante

<!--
## Descripci√≥n del Lenguaje L√©xico: par√°metros de entrada de la funci√≥n 

El l√©xico del lenguaje se describe mediante un array de pares `[String, /regExp/]`:

```js
[[nombreDelToken1, /regExpDelToken1/] ... [nombreDelTokenN, /regExpDelTokenN/]
```

Sigue un ejemplo de descripci√≥n de un analizador l√©xico 
para un peque√±o lenguaje:

```js
const SPACE = /(?<SPACE>\s+)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>\b([a-z_]\w*))\b/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const myTokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID],
  ['STRING', STRING], ['OP', OP]
];

```
-->

## Sugerencias

Puede partir de este c√≥digo en el que se combina el uso de sticky y los grupos con nombre


```js
const str = 'const varName = "value"';
console.log(str);

const SPACE = /(?<SPACE>\s+)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>([a-z_]\w+))/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const tokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID], 
  ['STRING', STRING], ['OP', OP] 
];

const tokenNames = tokens.map(t => t[0]);
const tokenRegs  = tokens.map(t => t[1]);

const buildOrRegexp = (regexps) => {
  const sources = regexps.map(r => r.source);
  const union = sources.join('|');
  // console.log(union);
  return new RegExp(union, 'y');
};

const regexp = buildOrRegexp(tokenRegs);

const getToken = (m) => tokenNames.find(tn => typeof m[tn] !== 'undefined');

let match;
while (match = regexp.exec(str)) {
  //console.log(match.groups);
  let t = getToken(match.groups);
  console.log(`Found token '${t}' with value '${match.groups[t]}'`);
}
```

escribiendo una funci√≥n `makeLexer` que recibe como argumentos un array `tokens`
como en el ejemplo y retorna una funci√≥n que hace el an√°lisis l√©xico 
correspondiente a esos tokens.

## Pruebas

Deber√° a√±adir pruebas usando [Jest]({{site.baseurl}}/assets/temas/introduccion-a-javascript/jest}). Ampl√≠e este ejemplo:

```
[~/.../github-actions-learning/lexer-generator(master)]$ pwd -P
/Users/casiano/local/src/github-actions-learning/lexer-generator
[~/.../github-actions-learning/lexer-generator(master)]$ cat test.js
```
```js
// If you want debugging output run it this way:
// DEBUG=1 npm test
const debug = process.env["DEBUG"];
const { inspect } = require('util');
const ins = (x) => { if (debug) console.log(inspect(x, {depth: null})) };

const buildLexer =require('./index');

const SPACE = /(?<SPACE>\s+|\/\/.*)/;
const RESERVEDWORD = /(?<RESERVEDWORD>\b(const|let)\b)/;
const ID = /(?<ID>\b([a-z_]\w*))\b/;
const STRING = /(?<STRING>"([^\\"]|\\.")*")/;
const OP = /(?<OP>[+*\/=-])/;

const myTokens = [
  ['SPACE', SPACE], ['RESERVEDWORD', RESERVEDWORD], ['ID', ID],
  ['STRING', STRING], ['OP', OP]
];

let str, lexer, r;
lexer = buildLexer(myTokens);

str = 'const varName = "value"';
ins(str);
r = lexer(str);
ins(r);
let expected = [
  { type: 'RESERVEDWORD', value: 'const' },
  { type: 'ID', value: 'varName' },
  { type: 'OP', value: '=' },
  { type: 'STRING', value: '"value"' }
];

test(str, () => {
  expect(r).toEqual(expected);
});

str = 'let x = a + \nb';
ins(str);
r = lexer(str);
expected = [
  { type: 'RESERVEDWORD', value: 'let' },
  { type: 'ID', value: 'x' },
  { type: 'OP', value: '=' },
  { type: 'ID', value: 'a' },
  { type: 'OP', value: '+' },
  { type: 'ID', value: 'b' }
];
ins(r);
test(str, () => {
  expect(r).toEqual(expected);
});

str = ' // Entrada con errores\nlet x = 42*c';
ins(str);
r = lexer(str);
ins(r);
expected = [
  { type: 'RESERVEDWORD', value: 'let' },
  { type: 'ID', value: 'x' },
  { type: 'OP', value: '=' },
  { type: 'ERROR', value: '42*c' }
];

test(str, () => {
  expect(r).toEqual(expected);
});
```

Ejemplo de ejecuci√≥n:

```
[~/.../github-actions-learning/lexer-generator(master)]$ npm test

> @ULL-ESIT-PL-2021/lexer-generator@1.0.0 test /Users/casiano/local/src/github-actions-learning/lexer-generator
> jest        üëà use jest!

 PASS  ./test.js
  ‚úì const varName = "value" (4ms)
  ‚úì let x = a +
b
  ‚úì  // Entrada con errores
let x = 42*c (1ms)

Test Suites: 1 passed, 1 total
Tests:       3 passed, 3 total
Snapshots:   0 total
Time:        1.126s
Ran all test suites.
```

## Integraci√≥n Cont√≠nua usando GitHub Actions

Use [GitHub Actions]({{site.baseurl}}/assets/temas/introduccion-a-javascript/github-actions) para la ejecuci√≥n de las pruebas

## Documentaci√≥n

[Documente]({{site.baseurl}}/assets/temas/introduccion-a-javascript/documentation)
el m√≥dulo incorporando un `README.md` y la documentaci√≥n de la funci√≥n exportada.

## Publicar como paquete npm en GitHub Registry

Usando el repo de la asignaci√≥n de esta tarea publique el paquete como paquete privado en GitHub Registry con √°mbito `@ULL-ESIT-PL-2021`  y nombre el nombre de su repo `lexgen-code-aluAtGitHub`

## Pruebas de Producci√≥n

En un nuevo repo `lexgen-testing-aluGitHub` a√±ada las pruebas
para comprobar que el paquete publicado 
se instala y puede ser usado correctamente.

Usando `git submodule` configure un super-repo para que contenga
a ambos repos: el del m√≥dulo `lexgen-code-aluAtGitHub` y el repo de pruebas de producci√≥n `lexgen-testing-aluGitHub`.

## Semantic Versioning

Publique una mejora en la funcionalidad del m√≥dulo. Por ejemplo a√±ada la opci√≥n `/u`
a la expresi√≥n regular creada para que Unicode sea soportado. ¬øComo debe cambiar el n¬∫ de versi√≥n?

## Referencias

* Tema [Expresiones Regulares y An√°lisis L√©xico]({{site.baseurl}}/temas/expresiones-regulares-y-analisis-lexico)  
* Secci√≥n [Creating and publishing a node.js module en GitHub y en NPM]({{site.baseurl}}/assets/temas/introduccion-a-javascript/creating-and-publishing-npm-module)
* [Jest]({{site.baseurl}}/assets/temas/introduccion-a-javascript/jest)
* Secci√≥n [GitHub Registry]({{site.baseurl}}/assets/temas/introduccion-a-javascript/github-registry)
* Secci√≥n [GitHub Actions]({{site.baseurl}}/assets/temas/introduccion-a-javascript/github-actions)
* Secci√≥n [M√≥dulos]({{site.baseurl}}/assets/temas/introduccion-a-javascript/modulos)
* Secci√≥n [Node.js Packages]({{site.baseurl}}/assets/temas/introduccion-a-javascript/nodejspackages)
* Secci√≥n [Documentation]({{site.baseurl}}/assets/temas/introduccion-a-javascript/documentation)
